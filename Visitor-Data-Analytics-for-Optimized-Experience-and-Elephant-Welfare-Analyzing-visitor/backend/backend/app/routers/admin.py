from fastapi import APIRouter, Depends
from app.ml_engine import ml_engine
from app.models import EventLog, Ticket
from datetime import datetime

router = APIRouter(
    prefix="/admin",
    tags=["Admin Analytics"]
)

@router.get("/analytics/suggestions")
async def get_schedule_suggestions():
    """
    Returns AI-driven schedule optimizations for the upcoming month.
    """
    next_month = (datetime.now().month % 12) + 1
    suggestions = ml_engine.optimize_schedule(next_month)
    return {
        "status": "success",
        "month": next_month,
        "suggestions": suggestions
    }

@router.get("/analytics/heatmap")
async def get_heatmap_data():
    """
    Returns aggregated visitor traffic data for heatmap visualization.
    AGGREGATED FROM REAL DB: EventLog collection.
    """
    # 1. Fetch Logs (Optimization: In prod, filter by date range, e.g., today)
    logs = await EventLog.find(EventLog.action == "check_in").to_list()
    
    # 2. Process Data
    density_map = {} # Key: (hour, location) -> count
    
    for log in logs:
        hour = log.timestamp.hour
        # map 24h to "09:00" format
        time_str = f"{hour:02d}:00"
        location = log.event_name
        
        key = (time_str, location)
        density_map[key] = density_map.get(key, 0) + 1
        
    # 3. Format & Normalize
    heatmap_data = []
    if not density_map:
        return {"status": "success", "data": []}
        
    max_count = max(density_map.values())
    
    for (time, location), count in density_map.items():
        intensity = int((count / max_count) * 100)
        heatmap_data.append({
            "time": time,
            "location": location,
            "intensity": intensity
        })
        
    # Sort by time
    heatmap_data.sort(key=lambda x: x["time"])
    
    return {
        "status": "success",
        "data": heatmap_data
    }

@router.get("/analytics/finance")
async def get_finance_data():
    """
    Returns financial metrics including Revenue, Ticket Sales, and Category Breakdown.
    AGGREGATED FROM REAL DB: Ticket collection.
    """
    tickets = await Ticket.find_all().to_list()
    
    total_tickets = 0
    total_revenue_usd = 0.0
    
    rev_foreign = 0.0
    rev_local = 0.0
    
    daily_sales_map = {day: 0 for day in ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]}
    
    # Exchange rate assumption for aggregation (LKR -> USD)
    LKR_TO_USD = 0.0033 
    
    for t in tickets:
        total_tickets += t.tickets_count
        
        # Normalize Revenue
        if t.currency == "LKR":
            usd_val = t.total_price * LKR_TO_USD
            rev_local += usd_val
        else:
            usd_val = t.total_price
            rev_foreign += usd_val
            
        total_revenue_usd += usd_val
        
        # Daily Sales
        day_name = t.booking_date.strftime("%a")
        if day_name in daily_sales_map:
            daily_sales_map[day_name] += int(usd_val) # Sales Value
            
    # Category Breakdown
    breakdown = [
        {"category": "Foreign (USD)", "revenue": round(rev_foreign, 2), "percentage": 0},
        {"category": "Local (LKR)", "revenue": round(rev_local, 2), "percentage": 0}
    ]
    
    # Calc Percentages
    if total_revenue_usd > 0:
        breakdown[0]["percentage"] = int((rev_foreign / total_revenue_usd) * 100)
        breakdown[1]["percentage"] = int((rev_local / total_revenue_usd) * 100)
        
    daily_sales_list = [{"day": k, "value": v} for k, v in daily_sales_map.items()]

    return {
        "status": "success",
        "data": {
            "total_revenue": round(total_revenue_usd, 2),
            "currency": "USD",
            "total_tickets": total_tickets,
            "revenue_growth": 0, # Requires historical comparison, 0 for now
            "category_breakdown": breakdown,
            "daily_sales": daily_sales_list
        }
    }

@router.get("/analytics/forecast")
async def get_forecast_data():
    """
    Returns the 14-day hourly forecast generated by the Advanced AI Model.
    Reads from: backend/datasets/advanced_hourly/forecast_14_days.csv
    """
    import pandas as pd
    import os
    
    # Path relative to where backend runs (assumed based on ML Engine)
    # We can use os.getcwd() or relative path from this file
    # Better to use absolute or relative safely
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    DATA_PATH = os.path.join(BASE_DIR, "datasets/advanced_hourly/forecast_14_days.csv")
    
    if not os.path.exists(DATA_PATH):
        return {"status": "error", "message": "Forecast data not found. Retrain model."}
        
    try:
        df = pd.read_csv(DATA_PATH)
        # Convert to list of dicts
        # We want a structure suitable for the chart: Array of objects
        # The CSV has: date, hour, location, event, predicted_visitors
        
        # Parse output:
        # We might want to group by Date/Hour for the X-Axis?
        # Or just return raw records and let Frontend Process? Raw is fine.
        records = df.to_dict(orient="records")
        
        return {
            "status": "success",
            "data": records
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}
